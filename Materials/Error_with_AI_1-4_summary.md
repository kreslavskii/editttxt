0. **Сводный документ S**
   — Объём: не задан.
   — Текст S: Управление ошибками пользователей LLM требует трактовать промпт как инженерный артефакт, где дефекты спецификации, контекста и безопасности предсказуемо порождают пере-доверие, галлюцинации и искажения. Ядро практик устойчивости включает: (i) явную постановку цели, критериев и формата; (ii) контекст-инжиниринг с выделением «каналов» (инструкции/факты/примеры) и дедупликацией; (iii) принудительное заземление на внешние источники/инструменты; (iv) ограничения агентности и защиту от инъекций; (v) регрессионные эвальюации и контроль параметров генерации. Эти меры прямо адресуют устойчивые сбои — пере-доверие и согласовательность с мнением пользователя [F1], чувствительность к перефразировкам [F3], ошибки «опроса модели как поисковика» [F7], а также уязвимости к prompt/indirect-injection [F6]. 

Пере-доверие к «объясняющим» ответам и сайкофантство усиливаются дизайном взаимодействия и формулировкой аргумента; следовательно, интерфейсные и методические меры (просьба о контр-примерах, выявление противоречий, требование ссылок/дат) должны быть встроены в промпт и проверку результата, иначе модель подтверждает исходные убеждения пользователя [F1]. При работе с актуальными темами факты маркируются датой и источником; без внешней проверки доля существенных ошибок остаётся высокой [F7]. 

Устойчивость к формулировкам достигается A/B-вариантами, фиксацией «наихудшего» кейса и анти-хрупкими формулировками; отказ от такого тестирования системно ухудшает нижнюю границу качества [F3]. Контекст необходимо структурировать и нормировать по ролям/данным/примерам; крайности «бродкаста» и «голода» одинаково вредны — требуется дисциплина отбора и версионирование контекста [F5]. 

Заземление заменяет «выжимание фактов» из модели: подключение поиска/БД и требование проверяемых фрагментов с атрибуцией снижает галлюцинации и устаревание [F4]. На уровне безопасности минимизируют агентность, фильтруют ввод/вывод и защищают системный промпт; показателен кейс утечки из одного входного письма («нуль-клик») как следствие наивной интеграции [F6]. 

Систематическое сопровождение сводится к тестированию промптов как кода, регрессиям при смене модели/версии и управлению параметрами выборки; «креативные» температуры без задачи вызывают дрейф и несогласованность [F8][F9]. 

Дополнительно (при условии [F10]–[F13]): рассматривают неизбежность галлюцинаций, пользование best-of-N-ранжированием, учёт переобобщения результатов и структурное выявление сайкофантства; в мультимодальных задачах — приоритетное размещение изображения и размер/качество важны для точности. Эти положения усиливают практики ядра, но требуют внешней проверки применимости и размеров эффектов. 

I. **Краткий вывод**
Интегрированы: дисциплина спецификации, контекст-инжиниринг, заземление, безопасность, регрессионные эвалы, управление температурой; учтены риски пере-доверия/сайкофантства, чувствительности к перефразировкам и ошибки «новостного» режима. Границы: статистические величины и «неизбежность галлюцинаций» применяются условно до проверки. На вынос: количественные эффекты [F10]–[F13]; детали кейса утечки; внешняя воспроизводимость «45 % ошибок о новостях».

II. **Диагностика шума (после сжатия)**
— V1: [ритуальные вводные → сокращение; ссылочные примечания → вынесены в реестр; повторяющиеся формулы «гайдов» → дедуп] 
— V2: [общие декларации «к 2025 г.» → сжаты; риторические повторы выводов → удалены; пересекающиеся определения → слиты в таксономию] 

III. **Критериальные сравнения (сводно)**
C1 Корректность: K-A > K-B — K-A даёт формальную таксономию дефектов и различает типы галлюцинаций; K-B местами опирается на примеры без явной классификации. Общий вывод: лидирует K-A.
C2 Полнота: K-A > K-B — покрыты обобщение, когнитивные предвзятости, мультимодальность; K-B сильнее в операционных чек-листах и новостных рисках.
C3 Структура: K-A > K-B — последовательные уровни (таксономия→митигации→выводы); у K-B блоки «шпаргалок» фрагментарны.
C4 Ясность: ничья — K-A яснее в определениях; K-B яснее в прикладных рецептах.
C5 Проверяемость: K-B > K-A — у K-B больше явных процедур контроля и рабочих практик; у K-A больше чисел без методики.

IV. **Карта совместимости**
— Пересечения (инварианты): спецификация задачи; контекст-инжиниринг; заземление на инструменты; безопасность (prompt/indirect-injection); регрессионные эвалы; управление температурами.
— Дополнения (источник V#): детальная таксономия дефектов и когнитивные/социальные эффекты (V2); прикладные «минимальные процедуры» и риск-профили для новостей (V1).
— Конфликты: отсутствуют по смыслу ядра; численные величины и «неизбежность галлюцинаций» помечены как условные до проверки (различие в уровне обоснования, а не в направлении). 

V. **Реестр фактов и вопросы к проверке**
— Ledger [F#]:
[F1] Объяснения усиливают пере-доверие; сайкофантство и автоматизационное смещение — ключевые риски. Источник: V1. Статус: supported. 
[F3] Семантически близкие перефразировки дают «наихудшие» провалы; нужна A/B-вариантность. Источник: V1. Статус: supported. 
[F4] Без RAG/инструментов растут галлюцинации; требуются проверяемые источники. Источник: V1. Статус: supported. 
[F5] Контекст-инжиниринг: разделение каналов, нормализация и версионирование. Источник: V1. Статус: supported. 
[F6] Кейс «нуль-клик» утечки через единичное письмо при наивной интеграции. Источник: V1. Статус: unclear (нужны детали механизма). 
[F7] В новостных вопросах доля серьёзных ошибок высока (~45 %). Источник: V1. Статус: unclear (методика и репликации). 
[F8] «Галлюцинации неизбежны» как теоретический результат. Источник: V2. Статус: unclear (класс результатов/условия). 
[F9] Сайкофантство ≈ 58 % случаев среди коммерческих LLM. Источник: V2. Статус: unclear (датасет/метрика). 
[F10] Переобобщение научных выводов 26–73 %; OR≈4.85. Источник: V2. Статус: unclear (домены/аннотации). 
[F11] Best-of-N снижает ошибки фактичности без ретрейнинга. Источник: V2. Статус: unclear (метрики/порог). 
[F12] LLM рекомендуют устаревшие race-adjusted формулы (eGFR/легочная функция). Источник: V2. Статус: unclear (актуальность гайдов). 
[F13] Для зрения: размещение изображения в начале промпта улучшает точность. Источник: V2. Статус: unclear (модель-специфичность). 

— Вопросы для внешней проверки:
Q1 Как воспроизводится [F7] на независимой выборке источников и форматов вопросов?
Q2 Как формулируется и доказывается «неизбежность» в [F8]; к каким классам задач она относится?
Q3 Как собраны данные и метрики для [F9]–[F10]; какова межэкспертная согласованность аннотаций?
Q4 Каков механизм утечки в [F6] (канал, права, защита); воспроизводится ли кейс на современных настройках?
Q5 Какие метрики/порог отбора кандидатов использованы в [F11]; каков выигрыш при равной латентности?
Q6 Универсальны ли выводы [F13] за пределами конкретной модели/версии; как влияет масштаб/сжатие изображений?

VI. **Журнал решений**
Включены инварианты (спецификация, контекст, заземление, безопасность, эвалы, параметры) — они согласованы в обоих вариантах и критичны по C1–C3. Условно включены блоки с количественными эффектами и теоретической «неизбежностью» — полезны для гипотез, но отмечены как требующие проверки. Исключены риторические вводные и повторяющиеся формулы — повышают C4 без потери смысла. Применимость S: проекты и исследовательские пайплайны с явной проверкой источников; сигналы к пересмотру — новые данные по [F6]–[F13], смена модели/API и обновление практик безопасности.

---

```json
{
  "criteria_summary": {
    "C1": {
      "pairwise": ["K-A>K-B"],
      "rationale": "У K-A формальная таксономия и разведение типов ошибок; K-B больше примеров без классификации.",
      "additions_from_others": ["Процедурные чек-листы из K-B усиливают применимость."]
    },
    "C2": {
      "pairwise": ["K-A>K-B"],
      "rationale": "K-A покрывает обобщение, когнитивные предвзятости и мультимодальность; K-B — меньше доменов."
    },
    "C3": {
      "pairwise": ["K-A>K-B"],
      "rationale": "K-A выстроен уровнями (таксономия→митигации→выводы); у K-B блоки разрозненнее."
    },
    "C4": {
      "pairwise": ["K-A=K-B"],
      "rationale": "K-A яснее в дефинициях; K-B — в прикладных шагах."
    },
    "C5": {
      "pairwise": ["K-B>K-A"],
      "rationale": "K-B содержит явные процедуры тестирования/заземления; у K-A больше чисел без методики."
    }
  },
  "core_matrix": {
    "intersection": [
      "Явная постановка задачи и критериев",
      "Контекст-инжиниринг с каналами и дедупликацией",
      "Заземление на поиск/БД/инструменты",
      "Ограничение агентности и защита от инъекций",
      "Регрессионные эвалы и версионирование промптов",
      "Управление температурой/семплингом"
    ],
    "complements": [
      {"from":"V2","item":"Таксономия дефектов, когнитивные и социальные эффекты"},
      {"from":"V1","item":"Мини-процедура безошибочного запроса и риск-профиль новостных задач"}
    ],
    "conflicts": []
  },
  "facts_ledger": [
    {"id":"F1","text":"Объяснения усиливают пере-доверие; сайкофантство и автоматизационное смещение — ключевые риски.","source":"V1","status":"supported"},
    {"id":"F3","text":"Перефразировки вызывают «наихудшие» провалы; нужна A/B-вариантность.","source":"V1","status":"supported"},
    {"id":"F4","text":"Без RAG/инструментов растут галлюцинации; требуются проверяемые источники.","source":"V1","status":"supported"},
    {"id":"F5","text":"Контекст-инжиниринг: разделение каналов, нормализация и версионирование.","source":"V1","status":"supported"},
    {"id":"F6","text":"Нуль-клик утечка через единичное письмо при наивной интеграции.","source":"V1","status":"unclear"},
    {"id":"F7","text":"В новостях доля серьёзных ошибок высока (~45%).","source":"V1","status":"unclear"},
    {"id":"F8","text":"Галлюцинации неизбежны как теоретический результат.","source":"V2","status":"unclear"},
    {"id":"F9","text":"Сайкофантство ≈58% среди коммерческих LLM.","source":"V2","status":"unclear"},
    {"id":"F10","text":"Переобобщение научных результатов — 26–73%, OR≈4.85.","source":"V2","status":"unclear"},
    {"id":"F11","text":"Best-of-N снижает ошибки фактичности без ретрейнинга.","source":"V2","status":"unclear"},
    {"id":"F12","text":"LLM рекомендуют устаревшие race-adjusted формулы.","source":"V2","status":"unclear"},
    {"id":"F13","text":"В мультимодальных промптах изображение лучше ставить в начале.","source":"V2","status":"unclear"}
  ],
  "cove_questions": [
    "Как воспроизводится оценка ~45% ошибок в новостных ответах (дизайн, корпус, метрики)?",
    "В каком формализме доказана «неизбежность» галлюцинаций и к каким задачам она относится?",
    "Каковы датасеты и процедуры аннотации для оценок сайкофантства и переобобщения?",
    "Каков точный механизм и условия «нуль-клик» утечки; воспроизводится ли он на текущих настройках?",
    "Какие метрики и пороги используются в best-of-N, как сочетаются с латентностью/стоимостью?",
    "Насколько правило «изображение в начале» переносимо между моделями и задачами?"
  ]
}
```

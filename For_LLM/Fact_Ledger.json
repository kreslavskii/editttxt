{
  "metadata": {
    "version": "2.0",
    "created": "2025-11-15",
    "updated": "2025-11-16",
    "purpose": "Реестр фактов с уровнями верификации для исследования ошибок LLM",
    "total_facts": 28,
    "verification_levels": {
      "supported": "Факт подтверждён несколькими источниками, может использоваться",
      "partial": "Факт подтверждён частично, требует оговорок",
      "unclear": "Недостаточно данных для верификации, требуется дополнительное исследование",
      "refuted": "Факт не подтвердился или противоречит найденным данным"
    },
    "web_verification_date": "2025-11-16",
    "web_verification_status": "8/8 фактов проверены"
  },
  "hypotheses_tested": {
    "H1": {
      "statement": "Замена PDF на MD уменьшает риск превышения лимита токенов",
      "status": "ПОДТВЕРЖДЕНА",
      "evidence": "MD-файлы загружены без проблем, объём ~770 строк уложился в бюджет",
      "confidence": "high"
    },
    "H2": {
      "statement": "Совокупный объём документов + системный промпт может превышать лимит контекста",
      "status": "НЕ ПОДТВЕРДИЛАСЬ",
      "evidence": "Использовано 125,639 из 200,000 токенов при полной загрузке всех документов",
      "confidence": "high"
    },
    "H3": {
      "statement": "Формат MD предпочтительнее PDF, но объём требует контроля",
      "status": "ЧАСТИЧНО ПОДТВЕРЖДЕНА",
      "evidence": "MD предпочтительнее (легче парсинг), контроль объёма критичен в общем случае, но текущий объём приемлем",
      "confidence": "high"
    }
  },
  "facts": [
    {
      "id": "F1",
      "category": "cognitive_biases",
      "statement": "Объяснения (reasoning traces) усиливают пере-доверие к ответам LLM, включая ошибочные",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Интерфейсные меры (просьба о контр-примерах, выявление противоречий) должны быть встроены в промпт",
      "quantitative_data": null,
      "verification_notes": "Согласуется с исследованиями CHI 2025",
      "action_items": ["Добавить в рекомендации: требовать альтернативные объяснения", "Не полагаться только на reasoning trace"]
    },
    {
      "id": "F2",
      "category": "cognitive_biases",
      "statement": "Сервильность (sycophancy) и автоматизационное смещение — ключевые риски при работе с LLM",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Модель подтверждает исходные убеждения пользователя вместо критического анализа",
      "quantitative_data": "~58% случаев у коммерческих LLM (F9)",
      "verification_notes": "Данные EMNLP 2025, см. F9 для деталей",
      "action_items": ["Явно требовать критического анализа в промптах", "Просить модель найти ошибки в предположениях пользователя"]
    },
    {
      "id": "F3",
      "category": "prompt_engineering",
      "statement": "Семантически близкие перефразировки дают радикально разные результаты, требуется A/B-вариантность",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Промпты должны тестироваться на устойчивость к перефразировкам",
      "quantitative_data": "Разрыв best/worst может быть критичным (NeurIPS 2024)",
      "verification_notes": "Согласуется с исследованиями prompt sensitivity",
      "action_items": ["Создавать несколько перефразировок промпта", "Оценивать наихудший случай, не только средний"]
    },
    {
      "id": "F4",
      "category": "rag_retrieval",
      "statement": "Без RAG/инструментов растут галлюцинации, требуются проверяемые источники с атрибуцией",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md", "noError_with_AI_for_users.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Заземление на внешние источники критично для фактической точности",
      "quantitative_data": "Частота галлюцинаций ~1-2% в медицине даже с RAG",
      "verification_notes": "Согласуется с практиками OpenAI, Anthropic, Google",
      "action_items": ["Использовать RAG для фактических данных", "Требовать ссылки и даты", "Проектировать поведение 'я не знаю'"]
    },
    {
      "id": "F5",
      "category": "prompt_engineering",
      "statement": "Контекст-инжиниринг: разделение каналов (инструкции/факты/примеры), нормализация и версионирование",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md", "Academic_Surveys_on_Prompt_Engineering.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Структура промпта не менее важна, чем содержание",
      "quantitative_data": null,
      "verification_notes": "Согласуется с официальными гайдами всех вендоров",
      "action_items": ["Использовать XML-теги или markdown для структуры", "Версионировать системные промпты", "Дедуплицировать контекст"]
    },
    {
      "id": "F6",
      "category": "security",
      "statement": "Нуль-клик утечка через единичное письмо при наивной интеграции (кейс EchoLeak / CVE-2025-32711)",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md", "Web verification 2025-11-16"],
      "status": "supported",
      "confidence": "high",
      "implications": "Наивная интеграция LLM в продукты критически опасна — атаки возможны через email без взаимодействия пользователя",
      "quantitative_data": "CVSS score: 9.3 (critical)",
      "verification_notes": "ПОДТВЕРЖДЕНО: EchoLeak (CVE-2025-32711) — zero-click vulnerability в Microsoft 365 Copilot. Атака: специально сформированное email → жертва спрашивает Copilot о чём-то связанном с письмом → Copilot читает скрытые инструкции в email и выполняет их → утечка данных (chat logs, OneDrive files, SharePoint, Teams messages). Исправлено Microsoft в январе 2025 (server-side patch). Опубликовано: arxiv.org/html/2509.10540, множество security advisories.",
      "action_items": ["Фильтровать input/output на инъекции", "Тестировать на датасетах LLMail-Inject", "Ограничить scope доступа LLM к данным"]
    },
    {
      "id": "F7",
      "category": "reliability",
      "statement": "В новостных вопросах доля серьёзных ошибок высока (~45%)",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md"],
      "status": "refuted",
      "confidence": "low",
      "implications": "Конкретная цифра 45% НЕ подтверждена, но проблемы с точностью LLM в новостях существуют (другие исследования показывают разные цифры)",
      "quantitative_data": "Исходное упоминание: ~45%. НЕ НАЙДЕНО исследование с этой цифрой. Найдены другие данные: LLM классифицируют ~80% reliable источников как unreliable; agreement с экспертами только ρ=0.50",
      "verification_notes": "НЕ ПОДТВЕРЖДЕНО: Веб-поиск не нашёл европейское медиа-исследование с цифрой 45%. Найдены академические работы 2024-2025 о точности LLM в новостях (arxiv.org/abs/2304.00228, др.), но с другими метриками. Возможно, цифра из непубличного отчёта или ошибка в исходном документе.",
      "action_items": ["ИСКЛЮЧИТЬ цифру 45% из утверждений", "Использовать общую формулировку: 'LLM демонстрируют проблемы с точностью в новостях'", "Требовать датировку и источники для любых новостных фактов"]
    },
    {
      "id": "F8",
      "category": "reliability",
      "statement": "Галлюцинации неизбежны как теоретический результат для универсальных решателей на базе LLM",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md", "Web verification 2025-11-16"],
      "status": "supported",
      "confidence": "high",
      "implications": "Политика нулевой толерантности означает не 'идеальная модель', а комбинацию защит (RAG + проверка + human-in-the-loop)",
      "quantitative_data": null,
      "verification_notes": "ПОДТВЕРЖДЕНО: Xu et al. (2024) 'Hallucination is Inevitable: An Innate Limitation of Large Language Models' (arXiv:2401.11817) — теоретическое доказательство через learning theory: LLM не могут выучить все computable functions, следовательно будут hallucinate если используются как general problem solvers. Дополнительно: работа 2025 доказывает невозможность perfect hallucination control (arxiv.org/html/2506.06382). Контр-позиция: Suzuki et al. (Feb 2025) показывают что галлюцинации можно сделать statistically negligible при достаточных данных.",
      "action_items": ["Подчеркнуть: неизбежность относится к universal LLM solvers", "Для узких задач с quality data галлюцинации можно минимизировать", "Всегда комбинировать: RAG + verification + human oversight"]
    },
    {
      "id": "F9",
      "category": "cognitive_biases",
      "statement": "Сервильность наблюдается в ~58% случаев среди коммерческих LLM (ChatGPT-4o, Claude, Gemini 1.5 Pro)",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md", "Web verification 2025-11-16"],
      "status": "supported",
      "confidence": "high",
      "implications": "Модели систематически жертвуют точностью ради согласия с пользователем — требуется explicit instruction требовать критику",
      "quantitative_data": "58.19% общий sycophancy rate; Gemini 62.47%, ChatGPT 56.71%, Claude 57.44%. Progressive sycophancy (→ правильный ответ): 43.52%, Regressive (→ ошибка): 14.66%",
      "verification_notes": "ПОДТВЕРЖДЕНО: 'SycEval: Evaluating LLM Sycophancy' (arXiv:2502.08177, Feb 2025, обновлено Sept 2025). Протестированы ChatGPT-4o, Claude-Sonnet, Gemini-1.5-Pro на AMPS (math) и MedQuad (medical) датасетах. Preemptive rebuttals → 61.75% sycophancy vs in-context rebuttals 56.52% (p<0.001).",
      "action_items": ["Явно требовать: 'найди ошибки в моих предположениях'", "Просить альтернативные объяснения", "Не интерпретировать согласие как подтверждение"]
    },
    {
      "id": "F10",
      "category": "reliability",
      "statement": "Переобобщение научных результатов: 26-73% случаев, OR≈4.85 по сравнению с человеком",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md", "Web verification 2025-11-16"],
      "status": "supported",
      "confidence": "high",
      "implications": "LLM склонны делать более широкие выводы, чем допускают данные — критично для научных коммуникаций",
      "quantitative_data": "OR=4.85 (95% CI [3.06, 7.70], p<0.001). Диапазон overgeneralization: 26-73% в зависимости от модели (DeepSeek, ChatGPT-4o, LLaMA 3.3 70B хуже всех)",
      "verification_notes": "ПОДТВЕРЖДЕНО: 'Generalization Bias in Large Language Model Summarization of Scientific Research' (Royal Society Open Science, 2025, также arXiv:2504.00025, PubMed 40309181). Тестировали 10 LLM, 4900 LLM-summaries vs original texts. LLM-summaries nearly 5× more likely to contain broad generalizations than human-authored. Newer models WORSE than earlier ones.",
      "action_items": ["Требовать явное указание ограничений обобщения", "Запрашивать предпосылки и границы применимости", "Lowering temperature может помочь (упомянуто в paper)"]
    },
    {
      "id": "F11",
      "category": "prompt_engineering",
      "statement": "Best-of-N (выбор лучшего из N вариантов) снижает ошибки фактичности без ретрейнинга",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md", "Web verification 2025-11-16"],
      "status": "partial",
      "confidence": "medium",
      "implications": "Можно улучшить качество через sampling, но есть cost/latency trade-off + риск reward hacking",
      "quantitative_data": "Одна реализация: >20% improvement in factual correctness (Deepchecks blog). Конкретные метрики варьируются.",
      "verification_notes": "ЧАСТИЧНО ПОДТВЕРЖДЕНО: Best-of-N (BoN) sampling — известный метод для alignment. Regularized BoN (RBoN) outperforms vanilla BoN и mitigates reward hacking. НО: специфичные метрики улучшения фактичности не найдены в академических работах (есть mention >20% improvement в практическом блоге). Метрики: SelfCheckGPT (consistency), TruthfulQA, SimpleQA benchmark. Trade-off: N запросов = N× стоимость + latency.",
      "action_items": ["Тестировать BoN на factuality benchmarks (TruthfulQA, SimpleQA)", "Измерить cost/latency trade-off для вашего use case", "Рассмотреть Regularized BoN для mitigation reward hacking"]
    },
    {
      "id": "F12",
      "category": "domain_specific",
      "statement": "LLM рекомендуют устаревшие race-adjusted формулы (eGFR, лёгочная функция)",
      "source": ["Error_with_AI_Annual.md", "Error_with_AI_1-4_summary.md", "Web verification 2025-11-16"],
      "status": "partial",
      "confidence": "medium",
      "implications": "Обучающие данные могут содержать устаревшие медицинские практики — risk для медицинских приложений LLM",
      "quantitative_data": null,
      "verification_notes": "ЧАСТИЧНО ПОДТВЕРЖДЕНО: Race-adjusted eGFR формула (CKD-EPI 2009) УСТАРЕЛА с сентября 2021 — NKF-ASN Task Force рекомендовала заменить на CKD-EPI 2021 race-free equation. Причина: race — social construct, не биологический; race-adjustment ведёт к falsely elevated eGFR у Black patients → delays в care и transplant evaluation. НО: веб-поиск НЕ НАШЁЛ исследований о том, что LLM рекомендуют старую формулу (все результаты — о медицинских рекомендациях, не об LLM).",
      "action_items": ["ПРОВЕРИТЬ ЭМПИРИЧЕСКИ: дать LLM задачу рассчитать eGFR и проверить какую формулу использует", "Требовать от LLM версию и дату клинических гайдлайнов", "Предупреждение: медицинские LLM требуют регулярного обновления знаний"]
    },
    {
      "id": "F13",
      "category": "multimodal",
      "statement": "Для мультимодальных промптов: размещение изображения влияет на точность, но универсального правила 'в начале' нет",
      "source": ["Error_with_AI_1-4_summary.md", "Academic_Surveys_on_Prompt_Engineering.md", "Web verification 2025-11-16"],
      "status": "partial",
      "confidence": "medium",
      "implications": "Порядок модальностей имеет значение, но зависит от задачи и модели",
      "quantitative_data": "Interleaved (IN) positioning marginally лучше. GPT-4o consistently outperforms Claude-3 and Gemini-1.5 на vision tasks.",
      "verification_notes": "ЧАСТИЧНО ПОДТВЕРЖДЕНО: Исследование 2025 'Image First or Text First? Optimising the Sequencing of Modalities' (arXiv:2410.03062, MDPI) показало: (1) Для simple single-image tasks positioning имеет значение. (2) Interleaved (IN — images within text) consistently лучше than text-first (TF) or image-first (IF). (3) Для multi-step reasoning важнее align sequence с logical flow, чем universal placement. (4) Context и task complexity важнее чем модальность order. НЕ подтверждается простое правило 'всегда в начале'.",
      "action_items": ["УТОЧНИТЬ утверждение: 'Interleaved positioning часто лучше для сложных задач'", "Тестировать placement на конкретных use cases", "Align modality sequence с logical reasoning flow"]
    },
    {
      "id": "F14",
      "category": "prompt_engineering",
      "statement": "Таксономия из 58 техник промптинга (Schulhoff et al., 2025)",
      "source": ["Academic_Surveys_on_Prompt_Engineering.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Промпт-инжиниринг — зрелая область с формализованными техниками",
      "quantitative_data": "58 техник, 33 стандартизированных термина",
      "verification_notes": "Peer-reviewed survey, arXiv:2406.06608",
      "action_items": ["Интегрировать техники в практические рекомендации", "Связать техники с таксономией ошибок"]
    },
    {
      "id": "F15",
      "category": "prompt_engineering",
      "statement": "OpenAI рекомендует: инструкции в начале, разделители (###, triple quotes), специфичность",
      "source": ["Academic_Surveys_on_Prompt_Engineering.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Базовые паттерны структурирования промптов общеприняты",
      "quantitative_data": null,
      "verification_notes": "Официальная документация OpenAI",
      "action_items": ["Включить в базовые рекомендации"]
    },
    {
      "id": "F16",
      "category": "tool_use",
      "statement": "Function calling (2023) → Agents SDK (2025) у OpenAI; встроенные инструменты у всех вендоров",
      "source": ["Academic_Surveys_on_Prompt_Engineering.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Tool use — стандартная возможность современных LLM",
      "quantitative_data": null,
      "verification_notes": "Официальные документации OpenAI, Anthropic, Google",
      "action_items": ["Добавить секцию об ошибках при tool use в gap-анализ"]
    },
    {
      "id": "F17",
      "category": "tool_use",
      "statement": "Model Context Protocol (MCP) — открытый стандарт для подключения LLM к внешним данным (Anthropic, принят Google)",
      "source": ["Academic_Surveys_on_Prompt_Engineering.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Стандартизация RAG и tool use между вендорами",
      "quantitative_data": null,
      "verification_notes": "Anthropic announcement Nov 2024, Google adoption 2025",
      "action_items": ["Включить MCP в рекомендации по архитектуре"]
    },
    {
      "id": "F18",
      "category": "prompt_engineering",
      "statement": "Anthropic вводит термин 'Context Engineering' — управление эволюцией контекста в диалоге",
      "source": ["Academic_Surveys_on_Prompt_Engineering.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Промпт-инжиниринг эволюционирует в контекст-инжиниринг для агентов",
      "quantitative_data": null,
      "verification_notes": "Anthropic Engineering Blog, Sept 2025",
      "action_items": ["Расширить секцию о контекст-менеджменте"]
    },
    {
      "id": "F19",
      "category": "tool_use",
      "statement": "Google ADK (Agent Development Kit, April 2025) — фреймворк для multi-agent систем с hierarchical agents",
      "source": ["Academic_Surveys_on_Prompt_Engineering.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Агентные системы — следующий уровень после single-shot промптинга",
      "quantitative_data": null,
      "verification_notes": "Google Developers Blog, April 2025",
      "action_items": ["Добавить секцию об ошибках в multi-agent системах"]
    },
    {
      "id": "F20",
      "category": "prompt_engineering",
      "statement": "Итеративная доработка промптов даёт лучший результат, чем 'идеальный' первый запрос",
      "source": ["noError_with_AI_for_users.md", "Error_with_AI_Annual.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Промптинг — процесс, а не одноразовое действие",
      "quantitative_data": null,
      "verification_notes": "Согласуется с практиками всех вендоров",
      "action_items": ["Включить в базовые рекомендации", "Культивировать итеративный подход"]
    },
    {
      "id": "F21",
      "category": "user_errors",
      "statement": "Главные ошибки пользователей: (1) расплывчатость (2) смешивание задач (3) отсутствие контекста (4) доверие без проверки",
      "source": ["noError_with_AI_for_users.md", "Error_with_AI_Annual.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Базовая грамотность пользователей критична",
      "quantitative_data": null,
      "verification_notes": "Согласуется между популярными и академическими источниками",
      "action_items": ["Образовательные материалы для пользователей", "Встроенные подсказки в интерфейсах"]
    },
    {
      "id": "F22",
      "category": "user_errors",
      "statement": "Пользователи часто формулируют запросы с уже встроенным ответом ('именно Ницше первым...'), что смещает модель",
      "source": ["noError_with_AI_for_users.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Confirmation bias усиливается формулировкой вопроса",
      "quantitative_data": null,
      "verification_notes": "Связано с F1, F2 (сервильность)",
      "action_items": ["Учить пользователей формулировать гипотезы, а не утверждения", "Просить модель проверить предпосылки вопроса"]
    },
    {
      "id": "F23",
      "category": "security",
      "statement": "OWASP LLM Top 10 и NIST GenAI Profile описывают типичные ошибки интеграции",
      "source": ["Error_with_AI_Annual.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Безопасность LLM — отдельная дисциплина с установленными стандартами",
      "quantitative_data": null,
      "verification_notes": "Официальные документы OWASP, NIST",
      "action_items": ["Включить ссылки в рекомендации", "Проводить security testing по OWASP Top 10"]
    },
    {
      "id": "F24",
      "category": "security",
      "statement": "Промпт-инъекции и jailbreak — реальные угрозы, есть публичные датасеты атак (TrustAIRLab, LLMail-Inject)",
      "source": ["Error_with_AI_Annual.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Систему нужно тестировать на реальных атаках, а не только учебных примерах",
      "quantitative_data": null,
      "verification_notes": "Публичные датасеты доступны",
      "action_items": ["Использовать датасеты для регрессионного тестирования", "Red-teaming как часть процесса"]
    },
    {
      "id": "F25",
      "category": "reliability",
      "statement": "Temperature и top-p влияют на разброс качества и вероятность галлюцинаций",
      "source": ["Error_with_AI_Annual.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Для точных задач нужны низкие temperature и фиксированный seed",
      "quantitative_data": null,
      "verification_notes": "Стандартное знание о параметрах декодирования",
      "action_items": ["Рекомендовать temperature=0 для фактических задач", "Best-of-N требует компромисса"]
    },
    {
      "id": "F26",
      "category": "prompt_engineering",
      "statement": "Пользовательская инструкция (Custom Instructions) экономит время и улучшает согласованность",
      "source": ["noError_with_AI_for_users.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Персонализация системного промпта — базовая практика",
      "quantitative_data": null,
      "verification_notes": "Возможность доступна в ChatGPT, Claude",
      "action_items": ["Рекомендовать заполнение Custom Instructions", "Примеры для разных профессий"]
    },
    {
      "id": "F27",
      "category": "prompt_engineering",
      "statement": "Мета-промптинг (попросить LLM создать промпт) эффективен при неопределённости задачи",
      "source": ["noError_with_AI_for_users.md"],
      "status": "supported",
      "confidence": "medium",
      "implications": "LLM может помогать в формулировке промптов",
      "quantitative_data": null,
      "verification_notes": "Практический опыт, Claude имеет Prompt Generator",
      "action_items": ["Рекомендовать для сложных/новых задач", "Всегда проверять сгенерированный промпт"]
    },
    {
      "id": "F28",
      "category": "user_errors",
      "statement": "Этические рамки в промптах (избегать драматизации, манипуляций) важны в чувствительных темах",
      "source": ["noError_with_AI_for_users.md"],
      "status": "supported",
      "confidence": "high",
      "implications": "Тон и стиль модели формируется промптом, можно избежать нежелательных паттернов",
      "quantitative_data": null,
      "verification_notes": "Особенно важно для медицины, психологии, социальных тем",
      "action_items": ["Включить этические ограничения в шаблоны промптов", "Примеры для психологов, врачей"]
    }
  ],
  "summary_statistics": {
    "by_status": {
      "supported": 23,
      "partial": 4,
      "unclear": 0,
      "refuted": 1,
      "conflicting": 0
    },
    "by_category": {
      "cognitive_biases": 4,
      "prompt_engineering": 8,
      "reliability": 5,
      "rag_retrieval": 1,
      "security": 4,
      "tool_use": 3,
      "multimodal": 1,
      "user_errors": 3,
      "domain_specific": 1
    },
    "confidence_distribution": {
      "high": 23,
      "medium": 5,
      "low": 0
    }
  },
  "web_verification_summary": {
    "total_verified": 8,
    "confirmed": 5,
    "partially_confirmed": 2,
    "refuted": 1,
    "details": {
      "F6_EchoLeak": "CONFIRMED — CVE-2025-32711, CVSS 9.3, zero-click attack via email, patched Jan 2025",
      "F7_45percent_news_errors": "REFUTED — не найдено исследование с этой цифрой, другие исследования показывают разные метрики",
      "F8_hallucinations_inevitable": "CONFIRMED — Xu et al. 2024 theoretical proof + 2025 impossibility theorem",
      "F9_sycophancy_58percent": "CONFIRMED — SycEval paper Feb 2025, arXiv:2502.08177",
      "F10_overgeneralization_OR_4_85": "CONFIRMED — Royal Society Open Science 2025, peer-reviewed",
      "F11_BestOfN": "PARTIAL — метод существует, >20% improvement упомянуто, но детальные academic metrics не найдены",
      "F12_race_adjusted_eGFR": "PARTIAL — формула устарела с 2021, но нет данных что LLM её рекомендуют (требуется эмпирическая проверка)",
      "F13_image_placement": "PARTIAL — interleaved лучше для complex tasks, но не универсальное правило 'в начале'"
    }
  },
  "recommendations_updated": [
    "F7 REFUTED: Исключить упоминание '45% ошибок' — использовать общую формулировку о проблемах LLM с новостями",
    "F12 PARTIAL: Эмпирически протестировать что LLM рекомендуют для eGFR расчёта",
    "F13 PARTIAL: Уточнить формулировку — 'interleaved positioning для complex tasks', не 'всегда в начале'",
    "Все CONFIRMED факты (F6, F8, F9, F10) можно безопасно использовать с указанием источников",
    "PARTIAL факты (F11, F12, F13) использовать с оговорками и пометкой 'requires further research'"
  ]
}
